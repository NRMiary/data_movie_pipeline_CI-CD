name: Data Cleaning and Compression

on:
  workflow_dispatch:
  workflow_run:  # Déclenche ce workflow lorsque le workflow "Data loading" est terminé
    workflows: ["Data loading"]  # Le nom du workflow principal
    types:
      - completed  # Ce workflow s'exécute lorsque le workflow "Data loading" est terminé

jobs:
  clean_and_compress:
    runs-on: ubuntu-latest  # Environnement Linux

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyarrow  # Installer pandas et pyarrow pour Parquet

      - name: Clean and Compress Data to Parquet
        run: |
          python scripts/data_cleaning_script.py  # Exécuter le script pour nettoyer et compresser les données en Parquet
      
      - name: Upload Parquet file
        uses: actions/upload-artifact@v3
        with:
          name: compressed-parquet-file  # Nom de l'artéfact
          path: output_data.parquet  # Chemin du fichier Parquet généré
